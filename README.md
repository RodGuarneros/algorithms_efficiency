# Big O Notation Explained: Time Complexity
Having in mind a cost of 1 micro-seconds by operation and the size of the input.
Here you can find examples of the followint algorithms:

-  𝑂(𝑛2) 𝑣𝑠 𝑂(𝑛3)
-  𝑂(𝑛) 𝑣𝑠 𝑂(𝑛log𝑛)

And more...

Knowledge is more important than ever. One key value of ChatGPT, as a language model based on Natural Language Processing, is getting a more critical base on its capacity for knowledge acquisition based on huge amounts of information in seconds. This is the main benefit from my point of view. That’s why it's really important to analyze an algorithm’s performance towards optimizing it, particularly if we think in the 175 billion parameters, 300 billion words for training, and $12 million in compute resources for Chat GPT.

With the training of this IA, computer scientists classify and analyze the behavior of an algorithm’s time with asymptotic complexity analysis, considering the question: How does the algorithm perform when input size goes toward infinity? It means tight bounds on performance in terms of using the notation named "Big O".

"Big O" notation often describes the worst-case upper bound or the longest an algorithm would run the maximal amount of space it would need in the worst case. 

Nowadays, ChatGPT can’t produce video, sound, or images like its brother Dall-E 2, but instead has an in-depth understanding of the spoken and written word.

The software has limited knowledge of the world until September 2021. It isn't aware of world leaders that came into power in 2021, and won't be able to answer questions about recent events.

Finally, get ready for something new and exciting, Open IA is developing the Chat GPT-4 and this language model is trained with five times more data than our current Chat GPT-3.

If you want to know more, please visit: 

For algorithm performance: https://github.com/RodGuarneros/algorithms_efficiency.git
For Chat GPT and their challenge: https://www.sciencefocus.com/future-technology/gpt-3/ 
For DALL·E 2: https://openai.com/dall-e-2/ 
